# Neural Networks for Natural Language Processing

This repository contains the exercises and projects for the Neural Networks for Natural Language Processing course.

## Exercise 1: Sentiment Analysis with Traditional ML

### Description

In this exercise, I implemented sentiment analysis using traditional machine learning techniques and simple neural networks.

### Key Concepts Covered

- Text preprocessing (tokenization, lemmatization, stop word removal)
- Feature extraction and encoding (TF-IDF, Bag of Words, word2vec)
- Traditional ML algorithms (Naive Bayes, SVM)
- Model evaluation and comparison metrics


## Exercise 2: Sentiment Analysis with Convolutions

### Description

In this exercise, I implemented a sentiment analysis model using CNNs. The model was trained to classify text into positive or negative sentiment.

### Key Concepts Covered

- Implemented the sentiment analysis model using CNNs.
- Explored different architectures and hyperparameters.
- Performed a mechanistic interpretability analysis of the model, visualizing the activations of the model.


## Exercise 3: Recurrent Networks for Sentiment Analysis

### Description

In this exercise, I implemented sentiment analysis using recurrent neural networks (RNNs). The model learned to capture sequential patterns in text data for sentiment classification.

### Key Concepts Covered

- Implemented RNN-based architectures (LSTM, GRU) for text classification
- Handled sequential data and variable-length inputs
- Explored bidirectional RNNs and attention mechanisms
- Compared performance with previous models (traditional ML and CNNs)


## Exercise 4: Transformers and Contextual Embeddings

### Description

In this exercise, I worked with transformer-based models and contextual embeddings for NLP tasks, focusing on sentiment analysis and beyond.

### Key Concepts Covered

- Used pre-trained transformer models like BERT
- Fine-tuned transformers for specific NLP tasks
- Leveraged contextual word embeddings
- Explored transfer learning in NLP
- Compared performance with previous architectures


